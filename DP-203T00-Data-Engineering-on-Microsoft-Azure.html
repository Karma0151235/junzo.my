<!DOCTYPE html>
<html lang="en" >
<head>
  <meta charset="UTF-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Junzo</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/logo.png" rel="icon">
  <link href="assets/img/logo.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300;0,400;0,500;0,600;0,700;1,300;1,400;1,600;1,700&family=Montserrat:ital,wght@0,300;0,400;0,500;0,600;0,700;1,300;1,400;1,500;1,600;1,700&family=Raleway:ital,wght@0,300;0,400;0,500;0,600;0,700;1,300;1,400;1,500;1,600;1,700&display=swap" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">
  <link href="assets/vendor/remixicon/remixicon.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/main.css" rel="stylesheet">
  <link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/Swiper/4.0.7/css/swiper.min.css'><link rel="stylesheet" href="assets/css/newsevent.css">
</head>
<body class="page-portfolio">
  
  <!-- ======= Header ======= -->
	<my-header></my-header>
	<script src="assets/js/header.js"></script>
  <!-- End Header -->
	
  <style>
	p {
	  margin-bottom: 2em;
	}


	.pageTitle,
	.pageSubTitle {
	  font-family: 'Titillium', sans-serif;
	  text-transform: uppercase;
	  color: #333;
	}

	.pageTitle {
	  color: #00008B;
	}

	.pageTitle {
	  font-size: 2em;
	  font-weight: 700;
	  line-height: 2em;
	}

	.pageSubTitle {
	  margin-bottom: 1em;
	  font-size: 1.4em;
	  font-weight: 300;
	}

	.background {
	  background:
	  background-size: 100% auto;
	  position: fixed;
	  width: 100%;
	  height: 300%;
	  top: 0;
	  left: 0;
	  z-index: -1
	}

	.wrapper {
	  width: 1020px;
	  padding: 40px;
	  margin: 20px auto;
	  background: #fff;
	  box-shadow:  0px 3px 3px 1px rgba(0, 0, 0, 0.25);
	}

	.slogan {
	  position: fixed;
	  display: block;
	  top: 700px;
	  width: 100%;
	  padding: 20px 0;
	  text-align: center;
	  background: #222;
	}

	.sloganTitle {
	  font-size: 70px;
	  font-weight: 700;
	  line-height: 80px;
	  color: #fff;

	  text-shadow: 0px 2px 1px rgba(0, 0, 0, 0.25);
	}
  </style>

  <main id="main">

    <!-- ======= Breadcrumbs ======= -->
    <div class="breadcrumbs d-flex align-items-center" style="background-image: url('assets/img/SAP-header.jpg');">
      <div class="container position-relative d-flex flex-column align-items-center">

        <h2 style="text-align: center;">DP-203T00 Data Engineering on Microsoft Azure</h2>
        <ol>
          <li><a href="index.html">Home</a></li>
          <li>DP-203T00 Data Engineering on Microsoft Azure</li>
        </ol>

      </div>
    </div><br><br><!-- End Breadcrumbs -->


    <!-- ======= Schedule Box ======= -->
    <style>
    table {
      font-family: arial, sans-serif;
      border-collapse: collapse;
      width: 67%;
    }

    td, th {
      border: 1px solid #dddddd;
      text-align: left;
      padding: 8px;
    }

    tr:nth-child(even) {
      background-color: white;
    }
    table.center {
      margin-left: auto;
      margin-right: auto;
    }
    </style>
  <table class="center">
  <tr>
    <th style="text-align: center;">Course</th>
    <th style="text-align: center;">Date</th>
    <th style="text-align: center;">Duration</th>
  </tr>
  <tr>
    <th rowspan="10" style="text-align: center;">DP-203T00 Data Engineering on Microsoft Azure</th>
    <td style="text-align: center;">Kindly contact us for more information</td>
	<th rowspan="10" style="text-align: center;">4 days </th>
  </tr>
 
</table>
    <!-- ======= End Schedule Box======= -->


    <!-- ======= Blog Section ======= -->
    <div class="background">
</div>

<article class="wrapper">
  <header>
    <h1 class="pageTitle">DP-203T00 Data Engineering on Microsoft Azure</h1>
  </header>
  <section>
    <h2 class="pageSubTitle"><b>WHAT YOU WILL LEARN</b></h2>
    <p style="text-align: justify;">In this course, the student will learn about the data engineering as 
it pertains to working with batch and real-time analytical solutions 
using Azure data platform technologies. Students will begin by 
understanding the core compute and storage technologies that are 
used to build an analytical solution. The students will learn how to 
interactively explore data stored in files in a data lake. They will 
learn the various ingestion techniques that can be used to load 
data using the Apache Spark capability found in Azure Synapse 
Analytics or Azure Databricks, or how to ingest using Azure Data 
Factory or Azure Synapse pipelines. The students will also learn the 
various ways they can transform the data using the same 
technologies that is used to ingest data. They will understand the 
importance of implementing security to ensure that the data is 
protected at rest or in transit. The student will then show how to 
create a real-time analytical system to create real-time analytical 
solutions. </p>

	<h2 class="pageSubTitle"><b>AUDIENCE</b></h2>
    <p>The primary audience for this course is data professionals, data 
architects, and business intelligence professionals who want to 
learn about data engineering and building analytical solutions using 
data platform technologies that exist on Microsoft Azure. The 
secondary audience for this course data analysts and data 
scientists who work with analytical solutions built on Microsoft 
Azure.</p><br>
	  
	  <h2 class="pageSubTitle"><b>PREREQUISITES</b></h2>
	  <p>Successful students start this course with knowledge of cloud 
computing and core data concepts and professional experience 
with data solutions. <br><br>Specifically: 
	  <li>AZ-900 - Azure Fundamentals </li>
	  <li>DP-900 - Microsoft Azure Data Fundamentals</li></p>
	  
	  <h2 class="pageSubTitle"><b>OBJECTIVES </b></h2>
	  After completing this course, students will be able to:  <br>
	  <li>Explore compute and storage options for data engineering 
workloads in Azure</li>
	  <li>Run interactive queries using serverless SQL pools </li>
	  <li>Perform data Exploration and Transformation in Azure 
Databricks</li>
	  <li>Explore, transform, and load data into the Data Warehouse 
using Apache Spark </li>
	  <li>Ingest and load Data into the Data Warehouse </li>
	  <li>Transform Data with Azure Data Factory or Azure Synapse 
Pipelines </li>
	  <li>Integrate Data from Notebooks with Azure Data Factory or 
Azure Synapse Pipelines </li>
	  <li>Support Hybrid Transactional Analytical Processing (HTAP) 
with Azure Synapse Link </li>
	  <li>Perform end-to-end security with Azure Synapse Analytics </li>
	  <li>Perform real-time Stream Processing with Stream Analytics</li>
	  <li>Create a Stream Processing Solution with Event Hubs and 
Azure Databricks </li>
	  
</section>
</article>
	  
  <article class="wrapper">
  <header>
    <h1 class="pageTitle">DP-203T00 Data Engineering on Microsoft Azure</h1>
  </header>
  <section>
    <h2 class="pageSubTitle"><b>COURSE CONTENTS </b></h2>
	  <b>Module 1: Explore compute and storage options for data 
engineering workloads</b>
	  <p style="text-align: justify;">In this module, you will learn how to provision an Azure Machine Learning workspace and use it to manage machine learning assets such as data, compute, model training code, logged metrics, and trained models. You will learn how to use the web-based Azure Machine Learning studio interface as well as the Azure Machine Learning SDK and developer tools like Visual Studio Code and Jupyter Notebooks to work with the assets in your workspace. </p>
	  
	  <b>Lessons</b>
	  <li>Introduction to Azure Synapse Analytics </li>
	  <li>Describe Azure Databricks </li>
	  <li>Introduction to Azure Data Lake storage </li>
	  <li>Describe Delta Lake architecture </li>
	  <li>Work with data streams by using Azure Stream Analytics </li><br>
	  
	  <b>Lab : Create an Azure Machine Learning Workspace </b><br>
	  After completing this module, you will be able to 
	  <li>Combine streaming and batch processing with a single 
pipeline</li>
	  <li>Organize the data lake into levels of file transformation </li>
	  <li>Index data lake storage for query and workload acceleration </li><br><br>
	  
	  After completing this module, students will be able to:<br>
	  <li>Describe Azure Synapse Analytics </li>
	  <li>Describe Azure Databricks </li>
	  <li>Describe Azure Data Lake storage </li>
	  <li>Describe Delta Lake architecture</li>
	  <li>Describe Azure Stream Analytics </li><br>
	  
	  <b>Module 2: Run interactive queries using Azure Synapse 
Analytics serverless SQL pools </b>
	  <p style="text-align: justify;">In this module, students will learn how to work with files stored in 
the data lake and external file sources, through T-SQL statements 
executed by a serverless SQL pool in Azure Synapse Analytics. 
Students will query Parquet files stored in a data lake, as well as 
CSV files stored in an external data store. Next, they will create 
Azure Active Directory security groups and enforce access to files in 
the data lake through Role-Based Access Control (RBAC) and 
Access Control Lists (ACLs). </p>
	  
	  <b>Lessons</b>
	  <li>Explore Azure Synapse serverless SQL pools capabilities</li>
	  <li>Query data in the lake using Azure Synapse serverless SQL 
pools </li>
	  <li>Create metadata objects in Azure Synapse serverless SQL 
pools </li>
	  <li>Secure data and manage users in Azure Synapse serverless 
SQL pools </li><br>
	  
	  <b>Lab : Run interactive queries using serverless SQL pools </b>
	  <li>Query Parquet data with serverless SQL pools </li>
	  <li>Create external tables for Parquet and CSV files </li>
	  <li>Create views with serverless SQL pools </li>
	  <li>Secure access to data in a data lake when using serverless SQL 
pools </li>
	  <li>Configure data lake security using Role-Based Access Control 
(RBAC) and Access Control List</li><br>
	  
	  After completing this module, students will be able to:<br>
	  <li>Understand Azure Synapse serverless SQL pools capabilities </li>
	  <li>Query data in the lake using Azure Synapse serverless SQL 
pools </li>
	  <li>Create metadata objects in Azure Synapse serverless SQL 
pools </li>
	  <li>Secure data and manage users in Azure Synapse serverless 
SQL pools </li>
	  
	  <b>Module 3: Data exploration and transformation in Azure 
Databricks</b>
	  <p style="text-align: justify;">This module teaches how to use various Apache Spark DataFrame methods to explore and transform data in Azure Databricks. The student will learn how to perform standard DataFrame methods to explore and transform data. They will also learn how to perform 
more advanced tasks, such as removing duplicate data, manipulate date/time values, rename columns, and aggregate data.</p>
	  
	  <b>Lessons</b>
	  <li>Describe Azure Databricks </li>
	  <li>Read and write data in Azure Databricks</li>
	  <li>Work with DataFrames in Azure Databricks </li>
	  <li>Work with DataFrames advanced methods in Azure Databricks </li>
	  
	  <b>Lab : Data Exploration and Transformation in Azure Databricks </b>
	  <li>Use DataFrames in Azure Databricks to explore and filter data</li>
	  <li>Cache a DataFrame for faster subsequent queries </li>
	  <li>Remove duplicate data </li>
	  <li>Manipulate date/time values</li>
	  <li>Remove and rename DataFrame columns </li>
	  <li>Aggregate data stored in a DataFrame </li><br>
	  
	  After completing this module, students will be able to:<br>
	  <li>Describe Azure Databricks </li>
	  <li>Read and write data in Azure Databricks </li>
	  <li>Work with DataFrames in Azure Databricks </li>
	  <li>Work with DataFrames advanced methods in Azure Databricks </li>
	  </section>
</article>
	  
	  
  <article class="wrapper">
  <header>
    <h1 class="pageTitle">DP-203T00 Data Engineering on Microsoft Azure</h1>
  </header>
  <section>
	  
	  <b>Module 4: Explore, transform, and load data into the Data Warehouse using Apache Spark </b><br>
	  <p style="text-align: justify;">This module teaches how to explore data stored in a data lake, 
transform the data, and load data into a relational data store. The 
student will explore Parquet and JSON files and use techniques to 
query and transform JSON files with hierarchical structures. Then 
the student will use Apache Spark to load data into the data 
warehouse and join Parquet data in the data lake with data in the 
dedicated SQL pool.</p>
	  
	  <b>Lessons</b><br>
	  <li>Introduction to Pipelines </li>
	  <li>Publishing and Running Pipelines </li><br>
	  
	  <b>Lab : Create a Pipeline </b><br>
	  <li>Understand big data engineering with Apache Spark in Azure 
		Synapse Analytics </li>
		<li>Ingest data with Apache Spark notebooks in Azure Synapse 
		Analytics </li>
		<li>Transform data with DataFrames in Apache Spark Pools in 
		Azure Synapse Analytics </li>
		<li>Integrate SQL and Apache Spark pools in Azure Synapse 
		Analytics </li><br>
	  
	  <b>Lab : Explore, transform, and load data into the Data Warehouse 
using Apache Spark </b><br>
	  <li>Perform Data Exploration in Synapse Studio </li>
	<li>Ingest data with Spark notebooks in Azure Synapse Analytics</li> 
	<li>Transform data with DataFrames in Spark pools in Azure 
	Synapse Analytics</li> 
	<li>Integrate SQL and Spark pools in Azure Synapse Analytics </li><br>
	
	After completing this module, students will be able to: 
	<li>Describe big data engineering with Apache Spark in Azure 
	Synapse Analytics </li>
	<li>Ingest data with Apache Spark notebooks in Azure Synapse 
	Analytics </li>
	<li>Transform data with DataFrames in Apache Spark Pools in 
	Azure Synapse Analytics</li> 
	<li>Integrate SQL and Apache Spark pools in Azure Synapse 
	Analytics</li>
	  
	<b>Module 5: Ingest and load data into the data warehouse </b><br>
	  <p style="text-align: justify;">This module teaches students how to ingest data into the data warehouse through T-SQL scripts and Synapse Analytics integration pipelines. The student will learn how to load data into Synapse dedicated SQL pools with PolyBase and COPY using T-SQL. The 
student will also learn how to use workload management along with a Copy activity in a Azure Synapse pipeline for petabyte-scale 
data ingestion. </p>
	  
	  <b>Lessons</b><br>
	  <li>Use data loading best practices in Azure Synapse Analytics</li> 
		<li>Petabyte-scale ingestion with Azure Data Factory </li><br>
	  
	  <b>Lab : Ingest and load Data into the Data Warehouse </b><br>
	  <li>Perform petabyte-scale ingestion with Azure Synapse 
		Pipelines</li> 
		<li>Import data with PolyBase and COPY using T-SQL</li> 
		<li>Use data loading best practices in Azure Synapse Analytics </li><br><br>
	  
	  After completing this module, students will be able to: 
	<li>Use data loading best practices in Azure Synapse Analytics </li>
	<li>Petabyte-scale ingestion with Azure Data Factory</li><br> 
	  
</section>
</article>



    <!-- End Blog Section -->

	<!-- ======= Call To Action Section ======= -->
		<section id="call-to-action" class="call-to-action">
		  <div class="container" data-aos="fade-up">
			<div class="row justify-content-center">
			  <div class="col-lg-6 text-center">
				<h3>Contact Us for More Information</h3>
				<p>Interested with the training course? Need more information? Contact Us.</p>
				<a class="cta-btn" href="https://wa.me/601128584728 ">Contact Us</a>
			  </div>
			</div>

		  </div>
		</section><!-- End Call To Action Section -->

  <!-- Footer -->
	<my-footer></my-footer>
	<script src="assets/js/footer.js"></script>
  <!-- End Footer -->

<a href="#" class="scroll-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

<div id="preloader"></div>

<!-- Vendor JS Files -->
<script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
<script src="assets/vendor/aos/aos.js"></script>
<script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
<script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
<script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
<script src="assets/vendor/php-email-form/validate.js"></script>

<!-- Template Main JS File -->
<script src="assets/js/main.js"></script>

<!-- partial -->
  <script src='https://codepen.io/pasaribu/pen/NNGbJo/c58fffe58d661ae3d4b168a43eb3b2b8.js'></script><script  src="assets/js/img.js"></script>
	  
<script>
  document.addEventListener("keydown", function (e) {
    if (e.key === "F12" ||
        (e.ctrlKey && e.shiftKey && e.key === "I") ||
        (e.ctrlKey && e.key === "U") ||
        (e.ctrlKey && e.key === "S") ||
        (e.ctrlKey && e.shiftKey && e.key === "J")) {
      e.preventDefault();
    }
  });

  // Prevent Right-Click Menu for "View Source"
  document.addEventListener("contextmenu", function (e) {
    e.preventDefault();
  });
</script>	  
	  
</body>
</html>
